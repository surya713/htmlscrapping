import urllib
from bs4 import BeautifulSoup
import nltk
import pprint

from nltk import word_tokenize, RegexpTokenizer, wordpunct_tokenize

url = "https://www.dropbox.com/privacy"
html = urllib.urlopen(url).read()
soup = BeautifulSoup(html, "html5lib")

# kill all script and style elements
for script in soup(["script", "style"]):
    script.extract()    # rip it out

# get text
text = soup.get_text()

# break into lines and remove leading and trailing space on each
lines = (line.strip() for line in text.splitlines())
# break multi-headlines into a line each
chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
# drop blank lines
text = '\n'.join(chunk for chunk in chunks if chunk)

# write to a file
# file = open("privacydropbox.txt", "w+")
# file.write(text.encode('utf8'))
# file.close()

# cleaning the text - tokenize the text
tokens = word_tokenize(text)
print len(tokens)
print tokens[:10]

# words without punctuations
tokenizer = RegexpTokenizer(r'\w+')
tokens_without_punc = tokenizer.tokenize(text)
print tokens_without_punc[:10]

# convert words to lower case
words = [w.lower() for w in tokens_without_punc]
print words[:10]

# get pos tags for words
pos_tags = nltk.pos_tag(words)
print pos_tags[:100]
